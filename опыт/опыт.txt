опыт
---------------------------------------------------------
профилирование приложений 		- pprof, trace
автоматизация развертывания приложений  - CI/CD
---------------------------------------------------------
БД
---------------------------------------------------------
Работал с postgre SQL, MS SQL, работал напрямую с запросами в базу через pgx и через GOrm, 
так же создавал индексы
Профилировал и оптимизировал запросы, работал с транзакциями и хранимыми процедурами. 
Немного знаю про шардирование и репликацию, но руками не делал

нереляционные бд:
- кеш редис, еластик документы
- работал как потребитель
- знаю что есть разные стратегии взаимодействия с кешом но не настраивал
+- знаю как внутри работает еластик, как в нём индексируются тексты по лексеммам, но не настраивал
---------------------------------------------------------
тестирование
---------------------------------------------------------
Писал юнит и интеграционные тесты, для юнитов использовался gomock, для интеграционных - использовал подготовленное скриптами окружение, в котором уже запускались (значащие) группы интеграционных тестов, чаще всего
интеграционные запускались в рамках ночного билда группами.
---------------------------------------------------------
написание кода
---------------------------------------------------------
В проектах была стандартная трехслойная архитектура (контроллер, сервис, репозиторий). Где-то была кодогенерация, 
и сервисы создавались по шаблону, где-то мы писали их сами, старались сделать поменьше. На одном из проектов использовали GIN, пользовался Gorilla Mux для роутинга.
---------------------------------------------------------
профилирование
---------------------------------------------------------
Для отладки приложения пользовался стандартными интсрументами golang: go benchmark (race флаг), trace, pprof
Как правило в сервисах были внедрены метрики и хелсчеки.
Иногда приходилось подключаться к приложению в проде дебаггером, на удивление занимало немного ресурсов и не сильно замедляло работу приложения (как я понял, за счет семплирования. sempl)
---------------------------------------------------------
работа с протоколами
---------------------------------------------------------
На всех проектах использовался RPC и где-то был HTTP. На одном проекте HTTP ручками писали сами, и они были доступны сразу из сервиса
На другом проекте мы перенесли HTTP ручки на gateway сервер для доступа извне, а сам он внутри дергал RPC
---------------------------------------------------------
шины данных (kafka, rabbit, sqs, nuts)
---------------------------------------------------------
Работал с kafka и rabbit (не достаточно быстро работает для бигтеха, примерно 10.000 RPS(запросы в секунду) то что заявляет разработчик), но от последнего постепенно отказывались
Я писал как сервисы-консьюмеры, так и продюсеры.
Стандартно ориентируюсь что такое топик(большие группы), партишн(отдельные каналы(жилы) данных), как распределяются сообщения по ключу, что такое консюмер группы.
Самостоятельно поддерживать кафка кластер не могу, но зайти и посмотреть, что происходит и поднять новый партишн, могу.
с кафка работал через внутренние библитиотеки от платформенных команд (под капотом конфлюенд кафка)
---------------------------------------------------------
Rabbit - умная шина данных на которой лежит ответственность за доставку сообщения получателям.
-----------------------------------------------------------
Kafka - журнал в который получатели сами должны приходить и читать нужные им данные

плюс отличие в выдерживаемой нагрузке - Rabbit ~10k сообщений, Kafka за счёт кластеризации сотни тысяч (400-600k)

Это распределенный брокер сообщений.
Асинхронная доставка большого количества сообщений

Миллионы сообщений в секунду
Развертывание - ноды

Торик кафки - журнал событий где хранятся сообщения (работает только на добавление данных). События в журнал неизменны

Продюсер - любой сервис код отправляет данные в кафку
Консюмер - сервис, вычитывающий данные из кафки

---------------------------------------------------------
контейнеризация, docker, cuber, linux
---------------------------------------------------------
SLA
Service Level Agreement = договорённость о сроках выполнения заявок

Grafana - система отображения графиков метрик

Kanban+Scrum
Kanban = методология принятия решений по выбору задач. Ближайший родственник - Scrum

у меня был Kanban разбитый на спринты
---------------------------------------------------------
defer
---------------------------------------------------------
для работы с мьютексами
для логирования конца работы метода
для закрытия канала
для работы с вейтгруппами
работа с внешними коннектами может быть ещё
или graceful shutdown
---------------------------------------------------------
Rest/Nuts
---------------------------------------------------------

набор принципов по постройке системы
rest - структура построения API:
0. клиент-серверная архитектура
1. унификация путей
2. управление системой через ресурсы/объекты
3. отсутствие состояний между запросами
4. возможность кешировать запросы
---------------------------------------------------------
ООП в go
---------------------------------------------------------
- инкапсуляция (области видимости и маленькая/большая буквы)
- полиморфизм (интерфейсы и тайп свитчи)
- декорирование структур или наследование (когда мы одну структуру помещаем внутрь другой и так получаем некое подобие наследования)
- дженерики и рефлексия с кодогенерацией (это уже синьорские ответы)


---------------------------------------------------------
context
---------------------------------------------------------
контекст используется для передачи данных по стеку вызова функций

func A(){
  func B(){
   func C(){
	}
       }
      }
вложенные вызовы - сквозь них насквозь пробрасывается контекст
---------------------------------------------------------
docker
---------------------------------------------------------
docker задачи: 
- создание и модификация образа, 
- передача конфиг файла девопсам, 
- разворачивание образа из регистра, 
- создание локального стенда из нескольких сервисов и шины между ними, 
- поднятие зависимостей для интеграционных тестов
---------------------------------------------------------
kuber 
---------------------------------------------------------
зайти на деплоймент, снять логи/ошибки, посмотреть конфигурацию, поправить сетевое взаимодействие (например порты)

swagger
---------------------------------------------------------
rest/http/api/rpc
---------------------------------------------------------
строил рестовые апи, могу написать ручки, но в последнее время мы старались переносить все http взаимодействие с фронтом на гейт вэй сервер, а он уже внутренним сервисам ходил по RPC, таким образом мы снижали необх поддерживать и генерировать http ручки


