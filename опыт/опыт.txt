
опыт
---------------------------------------------------------
профилирование приложений 		- pprof, trace
автоматизация развертывания приложений  - CI/CD
---------------------------------------------------------
БД
---------------------------------------------------------
Работал с postgre SQL, MS SQL, работал напрямую с запросами в базу через pgx и через GOrm, 
так же создавал индексы
Профилировал и оптимизировал запросы, работал с транзакциями и хранимыми процедурами. 
Немного знаю про шардирование и репликацию, но руками не делал
---------------------------------------------------------
тестирование
---------------------------------------------------------
Писал юнит и интеграционные тесты, для юнитов использовался gomock, интеграционные - использовал 
подготовленное скриптами окружение, в котором уже запускались (значащие) группы интеграционных тестов, чаще всего
интеграционные запускались в рамках ночного билда группами.
---------------------------------------------------------
написание кода
---------------------------------------------------------
В проектах была стандартная трехслойная архитектура (контроллер, сервис, репозиторий). Где-то была кодогенерация, 
и сервисы создавались по шаблону, где-то мы писали их сами, старались сделать поменьше. На одном из проектов использовали GIN, пользовался Gorilla Mux для роутинга.
---------------------------------------------------------
профилирование
---------------------------------------------------------
Для отладки приложения пользовался стандартными интсрументами golang: go benchmark (race флаг), trace, pprof
Как правило в сервисах были внедрены метрики и хелсчеки.
Иногда приходилось подключаться к приложению в проде дебаггером, на удивление занимало немного ресурсов и не сильно замедляло работу приложения (как я понял, за счет семплирования. sempl)
---------------------------------------------------------
работа с протоколами
---------------------------------------------------------
На всех проектах использовался RPC и где-то был HTTP. На одном проекте HTTP ручками писали сами, и они были доступны сразу из сервиса
На другом проекте мы перенесли HTTP ручки на gateway сервер для доступа извне, а сам он внутри дергал RPC
---------------------------------------------------------
шины данных (kafka, rabbit, sqs, nuts)
---------------------------------------------------------
Работал с kafka и rabbit (не достаточно быстро работает для бигтеха, примерно 10.000 RPS(запросы в секунду) то что заявляет разработчик), но от последнего постепенно отказывались
Я писал как сервисы-консьюмеры, так и продюсеры.
Стандартно ориентируюсь что такое топик(большие группы), партишн(отдельные каналы(жилы) данных), как распределяются сообщения по ключу, что такое консюмер группы.
Самостоятельно поддерживать кафка кластер не могу, но зайти и посмотреть, что происходит и поднять новый партишн, могу.
с кафка работал через внутренние библитиотеки от платформенных команд (под капотом конфлюенд кафка)
---------------------------------------------------------
контейнеризация, docker, cuber, linux
---------------------------------------------------------











