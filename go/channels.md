   В go каналы являются указателями

   горутины нужны для реализации параллелизма и асинхронщины + для уменьшения расходов для переключения контекста (для горутин это будет проще чем у потоков системных)

   <mark>Deadlock (Взаимная блокировка)</mark>

   Чтение или запись данных в канал блокирует горутину, и контроль передается свободной горутине. В ситуации, когда такие горутины отсутствуют, либо они все "спят", возникает deadlock, который приведет к аварийному завершению программы.

   Если попытаться считать данные из канала, в котором отсутствуют данные, планировщик заблокирует текущую горутину и разблокирует другую в надежде, что какая-либо горутина передаст данные в канал. То же самое произойдет в случае отправки данных: планировщик заблокирует передающую горутину, пока другая не считает данные из канала.
   Примером deadlock может быть main горутина, которая эксклюзивно производит операции с каналом.

   <mark>Закрытие канала</mark>

   В Go можно закрыть канал. Через закрытый канал невозможно передать или принять данные. Горутина может проверить закрыт канал или нет, используя следующую конструкцию: ```val, ok := <- channel```, где ok будет истиной в случае, если канал открыт или операция чтения может быть выполнена, иначе ok будет false, если канал закрыт и отсутствуют данных для чтения из него. Закрыть канал можно, используя встроенную функцию close, используя следующий синтаксис ```close(channel)```

   <mark>Размер буфера канала</mark>

   Каждая операция отправки данных в канал блокирует текущую горутину. По-умолчанию размер буфера канала равен 0, такой канал называется небуферизированным каналом. То есть все, что пишется в канал, сразу доступно для чтения.

   Когда размер буфера больше 0, горутина не блокируется до тех пор, пока буфер не будет заполнен. Когда буфер заполнен, любые значения, отправляемые через канал, добавляются к буферу, отбрасывая предыдущее значение, которое доступно для чтения (где горутина будет заблокирована). Но есть один подвох, операция чтения на буферизированном канале является жадной, таким образом, как только операция чтения началась, она не будет завершена до полного опустошения буфера. Это означает, что горутина будет считывать буфер канала без блокировки до тех пор, пока буфер не станет пустым.

   <mark>Однонаправленный канал</mark>

   Это канал, который может только либо считывать данные, либо записывать их.
Однонаправленный канал создается с использованием make, но с дополнительным стрелочным синтаксисом.

```
roc := make(<-chan int)
soc := make(chan<- int)
```

   <mark>Анонимные горутины</mark>
   
   Каналы могут работать с анонимными горутинами. 

```
func main() {
   fmt.Println("main() started")
   c := make(chan string)

   //launch anonymous goroutine
   go func(c chan string) {
       fmt.Println("Hello " + <-c + "!")
   }(c)

   c <- "John"
   fmt.Println("main() stopped")
}
```

   <mark>select</mark>

   select похож на switch без аргументов, но он может использоваться только для операций с каналами. Оператор select используется для выполнения операции только с одним из множества каналов, условно выбранного блоком case.

```
select {
case result := <-chan1:
    ...
case result := <-chan2:
    ...
```

   Оператор select является блокируемым, за исключением использования default. После выполнения одного из блоков case, горутина main будет разблокирована. 

   Если все блоки case являются блокируемыми, тогда select будет ждать до момента, пока один из блоков case разблокируется и будет выполнен. Если несколько или все канальные операции не блокируемы, тогда один из неблокируемых case будет выбран случайным образом (имеется ввиду случай, когда пришли одновременно данные из двух и более каналов).

   Для того, чтобы сделать все блоки case неблокируемыми, можно использовать каналы с буфером.

   <mark>default case</mark>

   оператор select поддерживает оператор default. Оператор default является неблокируемым.
оператор default делает блок select всегда неблокируемым. Это означает, что операции отправки и чтения на любом канале (не имеет значения будет ли канал с буфером или без) всегда будут неблокируемыми.

Если значение будет доступно на каком-либо канале, то select выполнит этот case. Если нет, то он немедленно выполнит default.

   <mark>Deadlock</mark>

Для того, чтобы избежать deadlock, можно использовать default. Чтобы операции с каналами стали неблокируемыми, планировщик Go не будет планировать горутины для отправки данных в канал, даже если данные не доступны на данный момент.

<mark>timeout</mark>

иногда необходимо, чтобы определенный сервис ответил за определенное время, если он не отвечает, тогда должен выполниться блок default. Этого можно добиться, используя case с канальными операциями, которые будут разблокированы после заданного времени. Такая канальная операция предоставляется функцией After из пакета (package) time. 

```
select {
case response := <-chan1:
     ...
case response := <-chan2:
    ...
case <-time.After(2 * time.Second):
    ...
}
```

Конструкция <-time.After(2 * time.Second) . горутина main будет разблокирована через 2 секунды. time.After создаёт канал, по которому посылаются метки времени с заданным интервалом.

   <mark>Пустой select</mark>

Подобно пустому ```for{}```, пустой ```select{}``` так же является валидным, но есть подвох. select блокируется до тех пор, пока один из блоков case не будет выполнен, но так как в пустом select отсутствуют блоки case, горутина не будет разблокирована, и как результат, мы получим deadlock.

   <mark>WaitGroup</mark>

   WaitGroup применяется, когда нужно узнать, что все горутины были выполнены (например, операция сложения запущенная в нескольких горутинах). Такая задача является прямо противоположной с select. Здесь нужно дождаться полного завершения всех горутин.

   Это структура со счетчиком, которая отслеживает сколько горутин вами было создано, и сколько из них было завершено. Достижение счетчиком нуля будет означать, что все горутины были выполнены.

```
func service(wg *sync.WaitGroup, instance int) {
    time.Sleep(2 * time.Second)
    fmt.Println("Service called on instance", instance)
    wg.Done() // decrement counter
}

func main() {
  fmt.Println("main() started")
  var wg sync.WaitGroup // create waitgroup (empty struct)

  for i := 1; i <= 3; i++ {
      wg.Add(1) // increment counter
      go service(&wg, i)
  }

  wg.Wait() // blocks here
  fmt.Println("main() stopped")
}
```

   внутри себя WaitGroup содержит приватные поля noCopy и state1. Структура имеет три метода: Add, Wait и Done

 - Метод Add принимает int аргумент, который является delta (дельтой) для счетчика WaitGroup. Где счетчик — это число со значением, по умолчанию равным 0. Он хранит число запущенных горутин. Когда WaitGroup создана, значение счетчика будет равно 0, и мы можем увеличивать его, передавая delta как параметр метода Add. Счетчик не понимает автоматически, когда была запущена программа, поэтому нам нужно вручную увеличивать его, используя функцию Add.

 - Метод Wait используется для блокировки текущей горутины, когда мы его вызываем. Как только счетчик достигнет 0, горутина будет разблокирована. Поэтому нам необходимо как-то уменьшать значение счетчика.

 - Метод Done уменьшает значение счетчика. Он не принимает никаких параметров. (если посмотреть исходники пакета sync, то можно увидеть, что внутри себя он просто вызывает Add(-1)).

   <mark>Пул воркеров</mark>

   пул воркеров — это набор горутин, работающих одновременно для определенной задачи. 

```
package main

import (
    "fmt"
    "time"
)

// worker than make squares
func sqrWorker(tasks <-chan int, results chan<- int, id int) {
    for num := range tasks {
        time.Sleep(time.Millisecond) // simulating blocking task
        fmt.Printf("[worker %v] Sending result by worker %v\n", id, id)
        results <- num * num
    }
}

func main() {
    fmt.Println("[main] main() started")

    tasks := make(chan int, 10)
    results := make(chan int, 10)

    // launching 3 worker goroutines
    for i := 0; i < 3; i++ {
        go sqrWorker(tasks, results, i)
    }

    // passing 5 tasks
    for i := 0; i < 5; i++ {
        tasks <- i * 2 // non-blocking as buffer capacity is 10
    }

    fmt.Println("[main] Wrote 5 tasks")

    // closing tasks
    close(tasks)

    // receving results from all workers
    for i := 0; i < 5; i++ {
        result := <-results // blocking because buffer is empty
        fmt.Println("[main] Result", i, ":", result)
    }

    fmt.Println("[main] main() stopped")
}
```

   1. Функция sqrWorker принимает канал tasks, канал results и id. Задача этой горутины — отправлять квадрат числа, полученного из канала tasks, в канал results.
   2. В функции main, мы создали каналы tasks и result с размером буфера, равной 10. Следовательно, любая операция отправки будет неблокируемой, пока буфер не заполнится.
   3. Затем мы порождаем несколько экземпляров sqrWorker в виде горутин с двумя вышеописанными каналами и параметром id, чтобы позже получить информацию о том, какой воркер выполняет задачу.
   4. Далее мы передали 5 значений каналу tasks, операция будет неблокируемой, так как размер буфера не превышен.
   5. Так как мы закончили с каналом tasks, закрываем его. В этом нет необходимости, но это сэкономит много времени в будущем, если появятся ошибки.
   6. Используя цикл for с 5ю итерациями, мы извлекаем результат из канала results. Так как операция чтения на пустом буфере является блокируемой, планировщик запустит горутину из пула воркеров. До тех пор, пока горутина не вернет результат, main будет заблокирован.
   7. Поскольку мы симулируем операцию блокировки в горутине, это приведет к вызову планировщиком другой доступной горутины для запуска. Когда горутина запустится, она запишет результат в канал results, а так как операция записи в канал с буфером является неблокируемым до тех пор, пока буфер не заполнен, блокировки при записи не произойдет. Таким образом как только одна из горутин завершится, запустятся другие горутины и считают данные из канала tasks. После того, как все горутины считают данные из tasks, цикл for завершится, а канал tasks будет пустым. Так же не произойдет ошибка deadlock, так как канал tasks был закрыт.
   8. Иногда все воркеры могут находиться в режиме ожидания, поэтому main программа будет работать до тех пор, пока канал results не будет пуст.
   9. После того, как все воркеры отработают, main восстановит контроль, выведет оставшиеся результаты из канала results, и продолжит выполнение.

Горутины весьма эффективны, когда они могут блокироваться. Если убрать вызов time.Sleep(), то только одна горутина будет выполняться, так как другие горутины не будут запланированы до тех пор, пока цикл не закончится и горутина не завершится.

   <mark>пример с концепцией WaitGroup для синхронизации горутин</mark>
   Используя предыдущий пример с WaitGroup, мы можем получить те же результаты, но более элегантно.
```
// worker than make squares
func sqrWorker(wg *sync.WaitGroup, tasks <-chan int, results chan<- int, instance int) {
    for num := range tasks {
        time.Sleep(time.Millisecond)
        fmt.Printf("[worker %v] Sending result by worker %v\n", instance, instance)
        results <- num * num
    }

    // done with worker
    wg.Done()
}

func main() {
    fmt.Println("[main] main() started")

    var wg sync.WaitGroup

    tasks := make(chan int, 10)
    results := make(chan int, 10)

    // launching 3 worker goroutines
    for i := 0; i < 3; i++ {
        wg.Add(1)
        go sqrWorker(&wg, tasks, results, i)
    }

    // passing 5 tasks
    for i := 0; i < 5; i++ {
        tasks <- i * 2 // non-blocking as buffer capacity is 10
    }

    fmt.Println("[main] Wrote 5 tasks")

    // closing tasks
    close(tasks)

    // wait until all workers done their job
    wg.Wait()

    // receving results from all workers
    for i := 0; i < 5; i++ {
        result := <-results // non-blocking because buffer is non-empty
        fmt.Println("[main] Result", i, ":", result)
    }

    fmt.Println("[main] main() stopped")
}
```

   В приведенном результате мы получили более аккуратный вывод, потому что операция чтения из канала results в main не блокируется так как канал results уже содержит данные из-за вызванного ранее wg.Wait(). Используя WaitGroup, мы можем предотвратить много (ненужных) переключений контекста (планирование горутин и их запуск), в данном случае 7 против 9 в предыдущем примере. Но при этом приходится ожидать завершения всех горутин.

   <mark>Мьютекс</mark>

   Мьютекс — это один из самых простых концепций в Go. 
   race condition(состоянии гонки). Горутины имеют независимый стек, следовательно нет необходимости в обмене данными между ними. Но, иногда, необходимо использовать общие данные между несколькими горутинами. В этом случае несколько горутин пытаются взаимодействовать с данными в общей области памяти, что иногда приводит к непредсказуемому результату.
   Мьютекс — это концепция в программировании, где только один поток может выполнять несколько операций одновременно. Это делается с помощью подпрограммы, получающей блокировку для выполнения любых манипуляции со значением, которое она должна изменить, а затем снимает блокировку после. Когда значение заблокировано, никакая другая подпрограмма не может читать или записывать его.

   В Go мьютексы — это структура данных, которую предоставляет пакет sync. В Go перед выполнением любой операции со значением, которое может вызвать race condition, мы получаем эксклюзивную блокировку, используя метод mutex.Lock(). любые переменные, находящиеся между Lock и Unlock, будут недоступны для других горутин до тех пор, пока не выполнится операция снятия блокировки.

```
package main

import (
    "fmt"
    "sync"
)

var i int // i == 0

// goroutine increment global variable i
func worker(wg *sync.WaitGroup, m *sync.Mutex) {
    m.Lock() // acquire lock
    i = i + 1
    m.Unlock() // release lock
    wg.Done()
}

func main() {
    var wg sync.WaitGroup
    var m sync.Mutex

    for i := 0; i < 1000; i++ {
        wg.Add(1)
        go worker(&wg, &m)
    }

    // wait until all 1000 goroutines are done
    wg.Wait()

    // value of i should be 1000
    fmt.Println("value of i after 1000 operations is", i)
}
```

можно проверить программу на race condition в Go, используя флаг race при запуске программы. ```go run -race program.go```
